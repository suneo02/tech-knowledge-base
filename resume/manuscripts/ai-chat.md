# 项目深挖底稿：AI-Chat 智能对话助手

- **定位**：面试口述脚本 & 答辩思维导图
- **基线版本**：2023.08 - 2024.03 | 核心开发者

## 1. 叙事构建逻辑 (Narrative Construction)

### 模块一：电梯演讲 (The Hook / 1 min)

**[业务背景]** 这是一个为金融分析师打造的 "Chat-to-Data" 智能辅助工具，类似于金融版的 ChatGPT，但更专注于实时数据分析和图表生成。
**[核心职责]** 我主要负责核心的**流式通信架构设计**和**高性能消息渲染引擎**。
**[最大痛点]** 当时最大的挑战是**高频流式渲染的性能瓶颈**。大模型每 50ms 推送一个 Token，直接渲染会导致 React 高频重绘，页面卡顿甚至假死；同时 AI 生成的复杂 Markdown（如表格）容易在流式输出中结构崩坏。
**[解决方案]** 为了解决这个问题，我基于 **Ant Design X** 深度定制，实现了一套**基于 RAF 的字符缓冲队列**来削峰填谷，并开发了**语义感知注入管道**来处理引用的无损插入。
**[最终收益]** 最终实现了**毫秒级的流畅打字机体验**，开发效率提升了 80%，且 SSE 方案相比 WebSocket 节省了 30% 的连接资源。

### 模块二：STAR 深度复盘 (The Deep Dive)

#### S (Background / 场景痛点)
不仅仅是做一个聊天窗口。我们的用户是金融分析师，他们需要一边看几十万行的 VisTable 表格，一边让 AI 生成分析报告。
场景痛点在于：
1.  **数据量大**：表格可能有百万级单元格。
2.  **更新频次高**：AI 生成速度快，每秒可能有 20+ 次状态更新。
3.  **格式复杂**：AI 返回的是 Markdown，其中包含表格、代码块和引用标记，流式传输时 HTML 标签经常未闭合。

#### T (Task / 限制条件)
任务目标非常明确：
1.  **极致流畅**：无论 AI 生成多快，UI 必须保持 60FPS，不能阻塞用户滚动。
2.  **结构稳定**：流式生成过程中，表格不能“抖动”，Markdown 渲染不能崩坏。
3.  **兼容性**：必须支持 HTTP/2 复用，且能穿透企业严格的防火墙（这也是放弃 WebSocket 的原因之一）。

#### A (Action / 关键决策与行动)

**1. 架构选型：Why SSE & Ant Design X?**
我没有选择通用的 WebSocket，而是坚持用了 **SSE (Server-Sent Events)**。
*   **决策理由**：ChatGPT 等大模型场景主要是单向传输，SSE 天然支持 HTTP/2 复用，没有心跳保活的复杂逻辑，且对企业防火墙更友好。
*   UI 层面，我引入了 **Ant Design X**。这不只是为了好看，而是看重它内置的 `EventSource` 解析器和流式生命周期管理，帮我们规避了 90% 的粘包/分包问题。

**2. 性能攻坚：RAF 缓冲策略 (Frame Buffering)**
*   **问题**：直接 `setState` 会导致 React 疯狂 Re-render，CPU 飙升。
*   **解决**：我实现了一个**缓冲队列**。
    *   后端推过来的 Token 先进队列（Buffer）。
    *   利用 `requestAnimationFrame` (RAF)，在每一帧的空闲时间（16ms 内）把队列里的 Token 合并成一个 Chunk。
    *   一次性执行 DOM 更新。
    *   这就像“零钱兑整”，把几百次细碎的更新合并成每秒 60 次的规律更新，CPU 占用率直接降了一半。

**3. 体验优化：语义感知注入 (Semantic-Aware Injection)**
*   **问题**：RAG 场景下，AI 会返回 `[1]` 这样的引用。如果这个标记插在 Markdown 表格行的末尾，会破坏表格结构（少了闭合的 `|`），导致渲染炸裂。
*   **解决**：我写了一个 **AST 级别的预处理管道**。
    *   在渲染前，正则检测当前文本是不是表格行。
    *   如果是，强制把引用标记插在最后一个 `|` 之前，而不是行末。
    *   采用了**倒序插入算法**，防止前面的插入影响后面的索引位置。

**4. 细节打磨：滚动锚定 (Scroll Anchoring)**
*   在加载历史消息时，为了防止页面内容跳变（Scroll Jumping），我手动计算了新旧 DOM 的高度差，并在 `layoutEffect` 中瞬间修正 `scrollTop`，用户完全无感。

#### R (Result / 结果与收益)
*   **性能**：实现了零卡顿的流式渲染体验，长对话场景下 FPS 稳定在 55+。
*   **质量**：解决了 Markdown 表格渲染崩坏的历史难题。
*   **沉淀**：总结了一套《Ant Design X 集成范式》，将业务 Agent 与 UI Parser 解耦，这套模式后来被推广到了公司内部的其他 AI 项目中。

## 2. 防御性推演 (Defensive Strategy)

### 策略 A：技术选型质疑 (Trade-off)

*   **Trigger**：为什么用 SSE 而不是 WebSocket？WebSocket 不是双向更灵活吗？
*   **A (脚本)**：
    *   **承认场景**：确实，如果是即时通讯（IM）场景，WebSocket 是首选。
    *   **抛出特异性**：但 AI 对话主要是 **"Request-Response Stream"** 模式，用户发一句，AI 回一大段。
    *   **对比收益**：SSE 是基于 HTTP 的，可以复用现有的鉴权、缓存和 HTTP/2 连接池。实测下来，SSE 方案比维护 WebSocket 长连接节省了 **30% 的服务器连接资源**，而且不需要处理复杂的断线重连和心跳包逻辑，开发维护成本更低。

### 策略 B：深度原理挖掘 (Under the Hood)

*   **Trigger**：你提到的 RAF 缓冲队列，具体是怎么实现的？如果一帧内没有 Token 怎么办？
*   **A (脚本)**：
    *   **原理**：核心是一个 `buffer` 数组和一个递归的 `requestAnimationFrame` 循环。
    *   **流程**：SSE `onMessage` 触发时，只做 `buffer.push(token)`，不触发 React 更新。RAF 循环中检查 `buffer.length`。
    *   **边界**：如果 `buffer` 为空，RAF 直接跳过，不执行 `setState`，避免无效渲染。如果有数据，`join('')` 后清空 buffer，执行一次 `editor.insertContent`。这保证了渲染频率永远不会超过屏幕刷新率（60Hz）。

### 策略 C：不足与反思 (Deficiency & Pivot)

*   **Trigger**：项目有什么遗憾或者做得不好的地方？
*   **A (脚本)**：
    *   **真诚的不足**：早期为了解决 Tab 切换数据不更新的问题，我偷懒在组件上加了 `key={Math.random()}` 强制销毁重建。
    *   **后果**：这导致每次切换 Tab，组件状态（比如用户的筛选条件、滚动位置）都丢了，体验很差。
    *   **Pivot (改进)**：后来我深刻反思了这个问题，去掉了随机 Key，改用 Redux 存储状态，配合 `useEffect` 精确控制数据更新。这件事也让我后来在 Code Review 中特别关注 `key` 的使用规范。

## 3. 模拟对练 (Simulation)

*   **Round 1**：SSE 如何处理断网重连？（答：AntD X 底层封装了 `EventSource`，结合 Exponential Backoff 指数退避策略自动重试。）
*   **Round 2**：如果 AI 输出的代码块特别长，高亮渲染卡顿怎么办？（答：异步分片渲染，或者只高亮可视区域的代码。）
*   **Round 3**：React 18 的 Concurrent Mode 对你的流式渲染有影响吗？（答：有，`useTransition` 可以降低流式更新的优先级，保证用户输入不卡顿，但 RAF 方案更底层、更可控。）
